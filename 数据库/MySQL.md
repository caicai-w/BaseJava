## 一、一条SQL的执行过程

### 1.建立连接

MySQL客户端/服务端通信协议是“半双工“的，这两端不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。what？tcp会给你控制吧！！

### 2.查询缓存

在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这个查询缓存在8.0之后都被删掉了，没这个功能了。

### 3.语法解析和预处理

分析器会对你的sql语法做词法分析和语法分析，会根据语法分析器的规则判断你这个输入是否满足mysql的语法。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等等。

### 4.查询优化

一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到它觉得最好的执行计划。优化器所在的工作就是在表里面有多个索引的时候，决定使用哪个索引，或者在一个语句有多表关联的时候，决定各个表的连接顺序。MySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的 `last_query_cost`的值来得到其计算当前查询的成本。

```mysql
show status like 'last_query_cost';
+-----------------+-------------+
|Variable_name    |Value        |
+-----------------+-------------+
|Last_query_cost  |6391.799000  |
+-----------------+-------------+
```

示例中的结果表示优化器认为大概需要做6391个数据页的随机查找才能完成上面的查询。这个结果是根据一些列的统计信息计算得来的，这些统计信息包括：每张表或者索引的页面个数、索引的基数、索引和数据行的长度、索引的分布情况等等。

有非常多的原因会导致MySQL选择错误的执行计划，比如统计信息不准确、不会考虑不受其控制的操作成本（用户自定义函数、存储过程）、MySQL认为的最优跟我们想的不一样（我们希望执行时间尽可能短，但MySQL值选择它认为成本小的，但成本小并不意味着执行时间短）等等。MySQL的查询优化器是一个非常复杂的部件，它使用了非常多的优化策略来生成一个最优的执行计划：

- 重新定义表的关联顺序（多张表关联查询时，并不一定按照SQL中指定的顺序进行，但有一些技巧可以指定关联顺序）
- 优化 `MIN()`和 `MAX()`函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值）
- 提前终止查询（比如：使用Limit时，查找到满足数量的结果集后会立即终止查询）

### 5.查询执行引擎

在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为 `handler API`。查询过程中的每一张表由一个 `handler`实例表示。实际上，MySQL在查询优化阶段就为每一张表创建了一个 `handler`实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。

### 6.返回结果

结果集的返回有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足①中所描述的通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。

## 二、InnoDB缓冲池

Innodb存储是基于磁盘，存储按照页进行管理，所以需要缓冲池来中和一下cpu和磁盘速度，在数据库读页的时候，先从磁盘读到缓冲池，下一次读的时候先看缓冲池有没有。对数据修改时，也修改缓冲池里的，再以一定的频率刷回磁盘，但它也不是你每次改了缓冲池之后就一定会触发刷盘操作，它使用了一种**检查点**机制。

### 缓冲池里的数据有什么呢？

有索引页，数据页，undo页，插入缓存，自适应哈希，锁信息，数据字典等，不能任务缓冲池只缓存数据页和索引页，只是他们占很大一部分而已。
毕竟缓存有限的，那么当容量不够了怎么办呢？一般情况下缓存里的数据都是通过LRU算法管理，Innodb在LRU基础上做了优化，它加入了midPoint，新读取到的页，虽然是最新访问的，但并不直接插到头部，而是放到LRU列表的midPoint位置，在LRU列表长度的5/8处，midPoint之后的都叫old列表，之前的都叫new 列表，可以认为new列表都是热点数据。

为什么不采用朴素LRU？比如你做了一个扫描全表的操作，这些操作其实这是在这一次用到了，如果你把真正的热点数据都替换掉了，下次就还要找磁盘。

LRU是来管理页的一种方式，数据刚启动的时候肯定是没有什么热点数据的，LRU是空的，页空间都是Free在管理，当来了新的页先看free有没有空间，如果没有就用LRU替换了。一般来说缓冲池的命中应该在95%以上，如果达不到可能就是全表扫描让LRU污染（真正的热点数据被搞没了）。

LRU List里面的页被修改之后，称为脏页，缓冲池里的页和磁盘里的不一致了，这时候这个页也会挂到Flush List上，这两个list不冲突。缓冲池允许有多个，页根据哈希值平均分配到不同的缓冲池实例。（当我查找页数据或者索引时，根据一个数据怎么确定是哪个缓冲池？还是说要遍历缓冲池。）

缓冲池里还有redo log缓冲，和额外的缓冲空间。
Innodb首先把redolog放在缓冲池，然后按照一定的频率刷到重做日志文件。redolog缓冲不需要很大，只要能存下1s的就可以，在下面三种情况时就把redolog刷到磁盘日志文件，你只要记得，只要redolog在磁盘上，数据就一定不会丢。
1.Master Thread每1s把重做日志缓冲刷到重做日志文件。
2.当有新事务提交的时候刷。
3.当重做缓冲池剩余空间小于1/2时刷。

## 三、checkPoint

checkPoint做的事情就是什么时候把脏页刷回磁盘，会将buffer中脏数据页和脏日志页都刷到磁盘，因为有了缓冲池的设计，比如你update或者delete一个操作，缓冲池中的页就是脏页，也就是比磁盘上要新，那么如何刷回磁盘。如果每一次有更新都刷盘开销太大，如果刷的不及时，万一宕机了，数据库不能恢复了也不行。
事务数据库系统普遍采用Write Ahead Log 策略，当事务提交时：**先写重做日志，再修改页。**，当数据库宕机时，只需要对checkpoint后的重做日志进行恢复。

那么checkPoint在什么时候产生？
比如缓冲池不够了，LRU算法会溢出最近最少使用的页，如果此页为脏页，就强制执行checkpoint，把脏页刷回磁盘。

InnoDB有两种checkPoint：
sharp checkPoint：默认的工作方式，是在数据库关闭时把所有脏页刷到磁盘，但是数据库在运行的时候肯定不能这样。
fuzzy checkPoint：
1）Master Thread checkPoint，对master thread发生的checkPoint差不多以每1s或者每10s的速度从缓冲池的脏页列表中刷一定比例的页到磁盘。
2）FLUSH_LRU_List：这个是为了保持有100个空闲页，不够了就从LRU后面摘掉一些，如果去掉的里面有脏页，就checkpoint。
3）async/sync flush checkpoint：同步刷盘还是异步刷盘。例如还有非常多的脏页没刷到磁盘(非常多是多少，有比例控制)，这时候会选择同步刷到磁盘，但这很少出现；如果脏页不是很多，可以选择异步刷到磁盘，如果脏页很少，可以暂时不刷脏页到磁盘。   
4）dirty page too much checkpoint：脏页太多时强制触发检查点，目的是为了保证缓存有足够的空闲空间。too much的比例由变量innodb_max_dirty_pages_pct 控制，MySQL 5.6默认的值为75，即当脏页占缓冲池的百分之75后，就强制刷一部分脏页到磁盘。

## 四、mysql日志

现在只说说mysql 的日志redolog 和 binlog ，redolog 是独属于 innodb 的日志，binlog 则是属于 server 层的日志。
常见的日志有：二进制日志（binlog）、通用查询日志（默认不开启）、慢查询日志、错误日志、事务日志（redolog）等。

### 1.二进制日志（binlog）
用来记录操作MySQL数据库中的写入性操作（包括增删改，但不包括查询），操作语句以事件的形式进行保存，描述数据更改。

二进制日志的主要作用有两个： 
1. 复制，配置了主从复制的时候，主服务器会将其产生的二进制日志发送到slave端，slave端会利用这个二进制日志的信息在本地重做，实现主从同步。  
2. 恢复，因为二进制日志包含了备份以后的所有更新，因此可以用于最大限度地恢复数据库。因此，建议二进制日志单独保存到一个磁盘上，以便磁盘损坏以后进行数据恢复。

### 2.慢查询日志 
慢查询日志记录的是查询较慢的SQL语句的日志，可用设置一个时间的阈值，查询超过这个阈值的查询语句，都会记录下来。

### 3.事务日志（redolog和undolog）
InnoDB引擎特有日志，使用事务日志，在修改表的数据时只需要修改其内存拷贝，再把修改日志记录到持久在硬盘上的事务日志中，不用每次都将修改的数据页刷到磁盘，事务日志采用追加的方式，因此写日志的操作是磁盘上一小块区域内的顺序I/O，所以事务日志写起来也挺快，内存中被修改的数据页在后台可以慢慢的刷回到磁盘。

如果事务日志写到了磁盘，但数据本身还没有写回磁盘，此时系统崩溃，存储引擎在重启时能够自动恢复这部分修改的数据。

#### 3.1 redolog是什么？

redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。
在概念上，innodb通过force log at commit机制实现事务的持久性，即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化。 
为了确保每次日志都能写入到事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。因为MySQL是工作在用户空间的，MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将os buffer中的日志刷到磁盘上的log file中。   
redolog 是物理日志，记录的是某个表的数据做了哪些修改，redolog 是固定大小的，也就是说后面的日志会覆盖前面的日志。

刷日志到磁盘有以下几种规则：  
1.发出commit动作时。已经说明过，commit发出后是否刷日志由变量 innodb_flush_log_at_trx_commit 控制。  
2.每秒刷一次。这个刷日志的频率由变量 innodb_flush_log_at_timeout 值决定，默认是1秒。要注意，这个刷日志频率和commit动作无关。  
3.当log buffer中已经使用的内存超过一半时。  
4.当有checkpoint时，checkpoint在一定程度上代表了刷到磁盘时日志所处的LSN位置。  

#### 3.2 数据更新过程

我们执行一个更新操作是这样的：读取对应的数据到内存—>更新数据—>写 redolog 日志—> redolog 状态为 prepare —>写 binlog 日志—>提交事务—> redolog 状态为 commit ，数据正式写入日志文件。我们发现 redolog 的提交方式为“两段式提交”，这样做的目的是为了数据恢复的时候确保数据恢复的准确性，因为数据恢复是通过备份的 binlog 来完成的，所以要确保 redolog 要和 binlog 一致。
前面说宕机有redolog，现在又说用binlog，到底用啥？

#### 3.2 undolog是什么？
undo log有两个作用：提供回滚和多个行版本控制(MVCC)。
在数据修改的时候，不仅记录了redo，还记录了相对应的undo，如果因为某些原因导致事务失败或回滚了，可以借助该undo进行回滚。  
undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的update记录。   
当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。有时候应用到行版本控制的时候，也是通过undo log来实现的：当读取的某一行被其他事务锁定时，它可以从undo log中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。 undo log是采用段(segment)的方式来记录的，每个undo操作在记录的时候占用一个undo log segment。另外，undo log也会产生redo log，因为undo log也要实现持久性保护。

#### 3.3 redolog和binlog区别？ 
redo log不是二进制日志。虽然二进制日志中也记录了innodb表的很多操作，也能实现重做的功能，但是它们之间有很大区别。

1.二进制日志是在存储引擎的上层产生的，不管是什么存储引擎，对数据库进行了修改都会产生二进制日志。而redo log是innodb层产生的，只记录该存储引擎中表的修改。并且二进制日志先于redo log被记录。  
2.二进制日志记录操作的方法是逻辑性的语句。即便它是基于行格式的记录方式，其本质也还是逻辑的SQL设置，如该行记录的每列的值是多少。而redo log是在物理格式上的日志，它记录的是数据库中每个页的修改。  
3.二进制日志只在每次事务提交的时候一次性写入缓存中的日志"文件"。而redo log在数据准备修改前写入缓存中的redo log中，然后才对缓存中的数据执行修改操作；而且保证在发出事务提交指令时，先向缓存中的redo log写入日志，写入完成后才执行提交动作。  
4.因为二进制日志只在提交的时候一次性写入，所以二进制日志中的记录方式和提交顺序有关，且一次提交对应一次记录。而redo log中是记录的物理页的修改，redo log文件中同一个事务可能多次记录，最后一个提交的事务记录会覆盖所有未提交的事务记录。例如事务T1，可能在redo log中记录了 T1-1,T1- 2,T1-3，T1* 共4个操作，其中 T1* 表示最后提交时的日志记录，所以对应的数据页最终状态是 T1* 对应的操作结果。而且redo log是并发写入的，不同事务之间的不同版本的记录会穿插写入到redo log文件中，例如可能redo log的记录方式如下： T1-1,T1-2,T2-1,T2- 2,T2*,T1-3,T1* 。     
5.事务日志记录的是物理页的情况，它具有幂等性，因此记录日志的方式极其简练。幂等性的意思是多次操作前后状态是一样的，例如新插入一行后又删除该行，前后状态没有变化。而二进制日志记录的是所有影响数据的操作，记录的内容较多。例如插入一行记录一次，删除该行又记录一次。   

#### 3.4 LSN 
LSN称为日志的逻辑序列号(log sequence number)，在innodb存储引擎中，lsn占用8个字节。LSN的值会随着日志的写入而逐渐增大。根据LSN，可以获取到几个有用的信息：
1.数据页的版本信息。 
2.写入的日志总量，通过LSN开始号码和结束号码可以计算出写入的日志量。  
3.可知道检查点的位置。  
实际上还可以获得很多隐式的信息。
LSN不仅存在于redo log中，还存在于数据页中，在每个数据页的头部，有一个fil_page_lsn记录了当前页最终的LSN值是多少。通过数据页中的LSN值和redo log中的LSN值比较，如果页中的LSN值小于redo log中LSN值，则表示数据丢失了一部分，这时候可以通过redo log的记录来恢复到redo log中记录的LSN值时的状态。redo log的lsn信息可以通过 show engine innodb status 来查看。MySQL 5.5版本的show结果中只有3条记录，没有pages flushed up to。
```
mysql> show engine innodb stauts
---
LOG
---
Log sequence number 2225502463
Log flushed up to   2225502463
Pages flushed up to 2225502463
Last checkpoint at  2225502463
0 pending log writes, 0 pending chkp writes
3201299 log i/o's done, 0.00 log i/o's/second
```
其中：

log sequence number就是当前的redo log(in buffer)中的lsn； 
log flushed up to是刷到redo log file on disk中的lsn； 
pages flushed up to是已经刷到磁盘数据页上的LSN； 
last checkpoint at是上一次检查点所在位置的LSN。 

innodb从执行修改语句开始： 
(1).首先修改内存中的数据页，并在数据页中记录LSN，暂且称之为data_in_buffer_lsn；  
(2).并且在修改数据页的同时(几乎是同时)向redo log in buffer中写入redo log，并记录下对应的LSN，暂且称之为redo_log_in_buffer_lsn； 
(3).写完buffer中的日志后，当触发了日志刷盘的几种规则时，会向redo log file on disk刷入重做日志，并在该文件中记下对应的LSN，暂且称之为redo_log_on_disk_lsn； 
(4).数据页不可能永远只停留在内存中，在某些情况下，会触发checkpoint来将内存中的脏页(数据脏页和日志脏页)刷到磁盘，所以会在本次checkpoint脏页刷盘结束时，在redo log中记录checkpoint的LSN位置，暂且称之为checkpoint_lsn。 
(5).要记录checkpoint所在位置很快，只需简单的设置一个标志即可，但是刷数据页并不一定很快，例如这一次checkpoint要刷入的数据页非常多。也就是说要刷入所有的数据页需要一定的时间来完成，中途刷入的每个数据页都会记下当前页所在的LSN，暂且称之为data_page_on_disk_lsn。 

下面是一个刷盘的例子
![](https://user-gold-cdn.xitu.io/2018/9/18/165eb7a355b45652?imageslim)
上图中，从上到下的横线分别代表：时间轴、buffer中数据页中记录的LSN(data_in_buffer_lsn)、磁盘中数据页中记录的LSN(data_page_on_disk_lsn)、buffer中重做日志记录的LSN(redo_log_in_buffer_lsn)、磁盘中重做日志文件中记录的LSN(redo_log_on_disk_lsn)以及检查点记录的LSN(checkpoint_lsn)。

假设在最初时(12:0:00)所有的日志页和数据页都完成了刷盘，也记录好了检查点的LSN，这时它们的LSN都是完全一致的。

假设此时开启了一个事务，并立刻执行了一个update操作，执行完成后，buffer中的数据页和redo log都记录好了更新后的LSN值，假设为110。这时候如果执行 show engine innodb status 查看各LSN的值，即图中①处的位置状态，结果会是：

log sequence number(110) > log flushed up to(100) = pages flushed up to = last checkpoint at
之后又执行了一个delete语句，LSN增长到150。等到12:00:01时，触发redo log刷盘的规则(其中有一个规则是 innodb_flush_log_at_timeout 控制的默认日志刷盘频率为1秒)，这时redo log file on disk中的LSN会更新到和redo log in buffer的LSN一样，所以都等于150，这时  show engine innodb status ，即图中②的位置，结果将会是：

log sequence number(150) = log flushed up to > pages flushed up to(100) = last checkpoint at
再之后，执行了一个update语句，缓存中的LSN将增长到300，即图中③的位置。

假设随后检查点出现，即图中④的位置，正如前面所说，检查点会触发数据页和日志页刷盘，但需要一定的时间来完成，所以在数据页刷盘还未完成时，检查点的LSN还是上一次检查点的LSN，但此时磁盘上数据页和日志页的LSN已经增长了，即：

log sequence number > log flushed up to 和 pages flushed up to > last checkpoint at
但是log flushed up to和pages flushed up to的大小无法确定，因为日志刷盘可能快于数据刷盘，也可能等于，还可能是慢于。但是checkpoint机制有保护数据刷盘速度是慢于日志刷盘的：当数据刷盘速度超过日志刷盘时，将会暂时停止数据刷盘，等待日志刷盘进度超过数据刷盘。

等到数据页和日志页刷盘完毕，即到了位置⑤的时候，所有的LSN都等于300。

随着时间的推移到了12:00:02，即图中位置⑥，又触发了日志刷盘的规则，但此时buffer中的日志LSN和磁盘中的日志LSN是一致的，所以不执行日志刷盘，即此时 show engine innodb status 时各种lsn都相等。

随后执行了一个insert语句，假设buffer中的LSN增长到了800，即图中位置⑦。此时各种LSN的大小和位置①时一样。

随后执行了提交动作，即位置⑧。默认情况下，提交动作会触发日志刷盘，但不会触发数据刷盘，所以 show engine innodb status 的结果是：

log sequence number = log flushed up to > pages flushed up to = last checkpoint at
最后随着时间的推移，检查点再次出现，即图中位置⑨。但是这次检查点不会触发日志刷盘，因为日志的LSN在检查点出现之前已经同步了。假设这次数据刷盘速度极快，快到一瞬间内完成而无法捕捉到状态的变化，这时 show engine innodb status 的结果将是各种LSN相等。

#### 3.5 Innodb恢复行为
在启动innodb的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。

因为redo log记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如二进制日志)要快很多。而且，innodb自身也做了一定程度的优化，让恢复速度变得更快。

重启innodb时，checkpoint表示已经完整刷到磁盘上data page上的LSN，因此恢复时仅需要恢复从checkpoint开始的日志部分。例如，当数据库在上一次checkpoint的LSN为10000时宕机，且事务是已经提交过的状态。启动数据库时会检查磁盘中数据页的LSN，如果数据页的LSN小于日志中的LSN，则会从检查点开始恢复。

还有一种情况，在宕机前正处于checkpoint的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度。这时候一宕机，数据页中记录的LSN就会大于日志页中的LSN，在重启的恢复过程中会检查到这一情况，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。

另外，事务日志具有幂等性，所以多次操作得到同一结果的行为在日志中只记录一次。而二进制日志不具有幂等性，多次操作会全部记录下来，在恢复的时候会多次执行二进制日志中的记录，速度就慢得多。例如，某记录中id初始值为2，通过update将值设置为了3，后来又设置成了2，在事务日志中记录的将是无变化的页，根本无需恢复；而二进制会记录下两次update操作，恢复时也将执行这两次update操作，速度比事务日志恢复更慢。

## 五、Innodb关键特性

插入缓冲、两次写、自适应哈希索引、异步IO、刷新邻接页

#### 1.插入缓冲

InnoDB中，主键是行唯一的标志，通常应用程序中记录的插入顺序是按照主键的递增顺序进行插入。因此插入聚集索引都是顺序的，不用在磁盘上随机读。
但更多时候你需要去建一些非聚集索引去辅助查询，因为B+树叶子的数据根据主键顺序存放，所以可能用你建的索引去插入的时候就是离散的了。

所以对于非聚集索引中数据的的插入和更新，如果索引页在缓冲池就直接插入，如果缓冲池没有，就放到一个insert buffer对象中，再以一定的频率把insert buffer和辅助索引的叶子节点merge，这时通常可以把多个merge合并成一个操作。要想使用insert buffer需要满足两个条件：索引是辅助索引，索引不要求value唯一（如果要求唯一，那还要去索引页上找是不是唯一的，没法用）。

Change buffer是insert buffer的升级，可以分成：insert buffer，delete buffer，purge buffer，可以对insert、delete和update都进行缓冲。和insert一样change buffer适用的对象还是不唯一的辅助索引。

比如update操作，Delete buffer对应update的第一个操作，purge buffer对应update的第二个操作，即将真正的记录删除。

#### 2.两次写（double write）

部分写失效情况：如果在从缓冲中的数据页写到磁盘时，写到一半挂了。这样页就被损坏了，也许会想到用重做日志去恢复，但redo log存的是对页的物理操作，页已经坏了没办法恢复？？所以需要一个页副本，当写失效发生，先还原受损的页，再进行重做。
在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是先把脏页复制到内存中的double write buffer。

#### 3.自适应哈希

就是Innodb会监控B+索引，如果它觉得给你建和自适应哈希会让查询速度更快就会给你建。自适应hash是根据缓冲池的B+树来构造，而且不要求对整张表建立hash索引，它会自动给某些热点页建立hash索引。
自适应hash有一个要求：对这个页的连续访问模式必须是一样的，例如对于（a，b）这样的联合索引页，访问方式可以是：
where a = xxx 或者 where a = xxx and b = xxx
必须是其中一种，不能两种交替，而且要以该模式访问100次，页通过该模式访问了N次，N=页中记录*1/16。

#### 4.异步IO（AIO）

为了提高性能，当前数据库都采用异步IO，用户发一个IO请求之后可以再发送一个IO请求，而且它可以把多个IO请求优化成一个，比如发了一个（8，6），（8，7），（8，8），AIO判断这些页是连续的，就可以发一个读（8，6）的IO。

#### 5.刷新邻接页

就是把脏页刷到磁盘时，会检查页所在的区还有没有其他脏页，如果有就一起刷回去。好处就是AIO可以把多个IO合成一个。

## 四、索引

索引做的事情：查找和排序。mysql支持的常见索引：B+，全文、hash

### 1.B+树索引

B+树索引可以分为聚簇索引和非聚簇索引。不管是聚簇还是非聚簇，内部都是B+树，即高度平衡的，叶子存放着所有的数据，聚簇和非聚簇不同的是叶子节点存放的是否是一整行的数据。
聚簇索引就是按照每张表的主键构造一颗B+，叶子节点存放整行数据，每个数据页通过双向链表连接。聚簇索引的存储在物理上并不是连续的，他们一是通过页之间的双向链表，二是页中的记录也通过双向链表维护。聚簇的好处就是对于范围查找和对于主键的排序查找非常快。
辅助索引（非聚簇索引），叶子并不包含行的全部记录，它除了存储辅助索引的value，每个叶子节点中的索引中还包含一个书签，书签指明去哪里找索引对应的行数据，也就是聚簇索引的健。一张表可以有多个辅助索引。（尽量不要用select *，避免回表）

### 2.不适合建B+的情况

关于什么时候适合➕B+索引，不是所有要查询的字段都适合，比如对于性别这种字段，就两个值，这样就完全没有必要，B+适合高选择性字段。Cardinality表示索引中不重复记录的预估值，应该让Cardinality/row尽可能接近1。
这个Cardinality你用show index的时候可以显示出来，但是这只是一个预估的值，他也不是每次修改索引都会更新的，所以你可以选择在数据库空闲的时间做analyze table操作，为了让优化器更好的为你工作，因为可能Cardinality非常小，查询优化器就不愿意走这个索引了。

B+索引叶子节点因为是链表链起来的（叶子节点里面的行数据也是链表链起来的），所以没办法做二分，那么，每个叶子节点有个page directionry，它是专门用来给叶子节点做二分的。

⚠️B+索引并不能找到一个给定健值所在的具体行，B+索引能找到的只是被查找数据所在的页，然后数据库通过把页读到内存，再在内存中进行查找，最后得到要查找的数据。

### 3.B+索引的使用

**（1）.联合索引**
联合索引也是一棵B+，联合索引除了特定查询需要，第二个好处是在某些场景下可以当作排序，比如我们给（a，b）建立了联合索引，所以下列语句优化器就会选择联合索引,因为b是在每一段a中排序的
select  ... from table where a=xxx order by b;
同样，对于（a，b，c）下面语句同样可以得到结果：
select ... from table where a=xxx order by b；
select ... from table where a=xxx and b =yyy order by c；
但是
select ... from table where a=xxx order by c不行，因为在a里面c不是排序的。

**（2）.覆盖索引**
就是从辅助索引就可以查到数据，就不需要再走聚簇索引了。而且还有一种 情况是比如有个表table。
select count(*) from table。如果这个表有辅助索引是会通过辅助索引去做count的，因为辅助索引小，肯定IO少。

**（3）.优化器选择不使用索引的情况**
有时候在进行查询的时候，直接走B+索引，也就是全表的一个扫描，多发生的范围查询和join连接。
比如用select * 对订单id进行某个范围的查询，如果走辅助索引还要去聚簇索引读取整行数据，这种情况就会直接使用聚簇索引。另外，索引查询优化器会帮我们做选择，但它去计算选择哪个索引更好的时候本身也会浪费时间，可以用use index强制走哪个索引。

**（4）.MRR优化**
Multi-range-read优化的目的就是减少磁盘的随机访问，把随机访问转换成较为顺序的访问，减少IO。
对于range类型的查询，使用mrr的好处：
在查找辅助索引时，首先根据得到的查询结果，按照主键进行排序，按照主键的顺序进行书签查找。（比如上个例子select * ，我用辅助索引，那要根据主键再去查聚簇索引，所以这个时候，如果给主键索引排个序，可能会减少IO），
减少缓冲池中页被替换的次数，
批量处理对键值的查询。

对于范围查询和join，mrr的优化方式是：
将查询得到的辅助索引放到一个缓存里，这时缓存里的辅助索引是键值排序的；将缓存中的键值用rowId进行排序，根据rowId的排序顺序来访问实际的数据文件。

##### 1.2 Fast Index Creation

在MySQL5.5版本之前，一个很糟糕的创建和删除索引的方式是：
当你要对索引进行DDL操作，会先创建一张临时表，然后把原表中的数据倒入进去，再把原表删除然后把临时表重命名为原来的表。
那么，如果是对一张大表的索引进行这样的操作，是非常耗时的，这段时间数据库是不对外提供服务的。InnoDB1.0之后的版本支持FIC，在创建辅助索引的时候可以对表加个S锁就行，但是这个时间段内也是不能修改的，只能读。

##### 1.3 Cardinality

前面也说了这是查询优化器会重要参考的一个参数。但是Cardinality不是实时更新的，比如一个数据量非常大的表，不可能在每次更新索引的时候都去更新Cardinality，那么InnoDB存储引擎对Cardinality的更新策略为：
1.表中1/16的数据已经发生过变化
2.表中发生变化的次数 > 2000000000
那么，Cardinality到底是怎么统计出来的呢？
1.取B+叶子节点的数量
2.随机拿8个叶子节点统计每个叶不同的记录个数。
3.然后（P1+...+P8）*A/8
这个数据只是采样得到的，所以可能你数据没变每一次算出来的结果也不同。

### 4.哈希索引

O (1)时间的算法，自适应hash不是DBA能干预的，hash只适用于=的情况，范围就不行了。能O(1)时间查找，但只能精确查找，不能范围查找。InnoDB存储引擎有个功能叫自适应哈希，当某个索引值被使用的非常频繁，会在B+之上再建立一个哈希索引。

### 5.全文索引

B+树索引也可以根据索引的前缀查找，比如
select * from blog where content like ‘xxx%’，但很多情况是需要‘%xxxx%’。MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。

### 6.倒排索引

全文索引使用倒排来实现，倒排是一种结构，和B+索引一样。
Innodb支持全文检索，并且是full inverted index的形式，就是单词对应的不仅有文档id，还显示在文档中第几个单词（DocumentId，Position）看做一个ilist，所以在全文检索的表中有两个列，一个是word字段，一个是ilist字段，并且word字段上有索引。
倒排索引需要把word放在一张表中，这个表成为辅助表，在Innodb引擎中，为了提高全文检索并行性能，共有6张辅助表。辅助表是持久表，放在磁盘上，然而Innodb存储引擎的全文索引中。
一张表只能有一个全文检索的索引。

### 7、MySQL采用B+树的原因

1.平均查找次数少。平衡树查找的时间和树的高度有关LogdN，d是每个节点的出度，红黑树的出度是2，但是B+树的出度很大，明显红黑树更高查找次数多。
2.可以减少IO操作。
数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。每次在一个节点中查询减少了IO的次数。
其他：为了减少磁盘 I/O 操作，磁盘不是严格按需读取，它每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，只需要很短的旋转时间，速度会非常快。

操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。并且可以利用预读特性，相邻的节点也能够被预先载入。



### 8、索引优化

1.在查询的时候，索引列不能是表达式的一部分，否则无法使用。

```
SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;
```

2.在多个列查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引.

```
SELECT film_id, actor_ id FROM sakila.film_actor
WHERE actor_id = 1 AND film_id = 1;
```

3.让选择性最强的索引列放在前面。
索引选择性强就是说不重复的索引值多。
4.对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。对于前缀长度的选取需要根据索引选择性来确定。
5.覆盖索引：索引包含所有需要查询的字段的值。
具有以下优点：
索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。
对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。

### 9、索引的优点

减少了服数据的查找次数。
帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表）。
将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。

### 10、索引使用的条件、适合和不适合

对于非常小的表、大部分情况下简单的全表描比建立索引更好；经常增删改的表也不适合建索引，重复数据非常多也不适合建索引。
适合的情况：主键适合做唯一索引，频繁作为查询条件的字段，外键也可以做索引。查询中
对于中到大型的表，索引就非常有效；
查询中排序的字段，排序字段如果通过索引访问会大大提高查询速度。
但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。

### 11.索引优化策略

1.最左前缀匹配，主键外键一定要建索引，对where，on，group by，order by中出现的列使用索引。

2.使用高效选择性字段当索引，索引列不参与计算，

## 五、锁

lock和latch
lock的对象是事务，用来锁定数据库中的对象，如表、页、行。并且一般lock的对象仅在事务commit或rollback后进行释放（不同隔离级别可能不一样）。

### 0.Innodb锁的类型

InnoDB引擎实现两种标准的行级锁：
共享锁，允许事务读一行数据
排他锁，允许事务删除或更新一行数据
Innodb支持多粒度锁定，允许行级锁和表级锁同时存在，为了支持多粒度锁定，Innodb还支持意向锁，就是事务希望在更细粒度加锁。意向锁可以理解为表锁，比如你想给记录里的r加锁，那你需要先给数据库A，表1，和页加上意向锁IX，最后给r上x锁，如果粗粒度的锁不成功，那么就要等上一个表锁完成。
Innodb支持的两种意向锁：
意向共享锁：事务想要获得一张表中某几行的共享锁
意向排他锁：事务想要获得一张表中某几行的排他锁。
因为Innodb支持的是行级锁，其实意向锁其实不会阻塞全表扫意外的任何请求。
![image.png](https://upload-images.jianshu.io/upload_images/12328609-a07e7b149ed18f85.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- 什么是一致性非锁定读，MVCC？
- 什么是一致性锁定读
- 行锁的三种算法

### 1.什么是一致性非锁定读？

一致性非锁定读是指InnoDB存储引擎通过行多版本控制的方式来读取当前执行时间数据库中行的数据，如果读取的行正在进行delete/update操作，读取不回因为有排他的行锁就等待，而是去读取行的快照数据。
快照数据是该行之前版本的数据，实现是通过undo字段来完成。这是InnoDB默认的读取方式，但是在不同的数据隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读，即使采用了，对于数据快照的定义也不同。
那么，快照数据其实就是当前行的数据之前的历史版本，每行记录可能有多个版本，一行可能有不止一个快照数据，一般称这种技术为行多版本技术，由此带来的并发控制，叫做多版本并发控制（MVCC）。
在事务隔离级别：读提交、可重复读中，虽然都使用一致性非锁定读，但是对于数据快照的定义是不一样的，在读提交中，每次读取的是行的最新一份快照数据，比如你在一个读取事务里面，读了两次，可能中间这个记录被删掉了，那你第二次读的时候这个数据就不存在了。但是，可重复读的话，它读取的是读取这个事务开始的行数据版本，如果这个读取事务没有结束，中间有人来更新了删掉了，但再次读取的话还是和第一次读取的数值一样，注意是同一个读事务。

### 2.什么是一致性锁定读？

某些情况下，需要强制读取的一致性，就需要加锁了
select  ...  for update对读取的行记录加一个X锁
select  ...  lock in share mode 对读取的行记录加S锁

### 3.行锁的三种算法

**1、Record Lock 单个行记录上的锁**
锁的是索引，如果这行没索引，那就会用隐式的主键进行锁定，
**2、间隙锁**
锁定一个范围，但不包含记录本身。
**3、Next-Key Lock**
间隙锁➕单个行记录上的锁两者结合，锁定一个范围，并且锁定记录本身。InnoDB都是采用这种算法锁定。

```
如果事务T1已经通过Next-Key Lock锁定了下面范围：
(10,11]、(11,13]
当插入新的记录12时，锁定范围会变成下面：
(10,11]、(11,12]、(12,13]
```

但是，如果查询的索引有唯一属性，就会把next-key-locks降级，变成Record Lock，仅锁住索引本身，而不是范围，这也只是在select * from t where
a = 5的情况，只能是在判断相等的时候。
但如果索引没有唯一约束，而查询又是等于的情况，比如select * from t where
a = 5，那么不仅会锁上a=5，如果a的值除了5还有1和7，那么同时也会锁上(1,5),(5,7)这两个范围。

##### 3.1 RR隔离级别怎么避免的幻读

比如你 select * from table where a > 2 for update，那锁住的不仅是大于2的每一行，而是对于2到正无穷这个范围加X锁，在这个范围内的任何插入都是不允许的，避免幻读。

[https://juejin.im/post/5d5671a2e51d45620821cea7](https://juejin.im/post/5d5671a2e51d45620821cea7)

## 六、故障恢复



## 七、分库分表

### 1.为什么要分库分表？

一个是单机MySQL QPS太高，第二个就是数据亮太大。

对于qps太高，你可以把数据分散到不同的库里面去，每个库分担一部分请求。第二个就是数据量太大，比如单表数据量上千万了，你就可以把一张表的拆成多个表。

### 2.分库分表的方式

首先，分库和分表是不同的概念，分表就是把一张表的数据拆到多个表里，因为innodb里的一颗B+树大概能存两千万的数据，而且数据量太大一条查询语句已经会执行的非常慢了。那对于分表，你可以把一张表的数据拆分到多个表里面去，比如，给司机分了10张表，可以用司机id%10来算这个司机id存储在哪张表里。这种拆分叫水平拆分，所有表的字段是一样的，只是数据不一样，所有的数据加起来才是完整的数据。这个分好的表也可以放到不同的库里面去，用多个库扛住更高的并发，也能实现存储的扩容。

还有一种拆分就是，垂直拆分，比如有一些字段是查询频率很高的字段，有些字段没人查，那可以把查询频率高的字段单拿出来做一张表，查询频率低的字段做一张表。这样的一个好处是，因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存保存更多的行。这种拆分一般在表层面做的更多一些。

那如果你拆完之后，一个库的大小还是不够，就可以把这些放到其他库里。或者是单机qps不够，那也可以当到多个库里面去。那这个分库的方式有两种，一种是range，就是每个库一段连续的数据，比如按照时间的范围来，但是这种方式比较容易产生热点问题，就是大部分请求都去冲着最新的数据去的，另一种是按照某个字段做hash，这个比较常用，比如说比如用司机hash(driverID)%库的数量，hash(driverID)%表的数量，这样去找在哪个表上。
优缺点：
range来分，好处在于说，后面扩容的时候，就很容易，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。hash分法，好处在于说，可以平均分配没给库的数据量和请求压力；坏处在于扩容起来比较麻烦，会有一个数据迁移过程。

### 3.怎么把单库单表迁移到分库分表上去？

假设，现在有一个单表600万数据的表，你现在把他分了三个库，每个库四个表，单表50万。怎么迁移？
一般来说就是双写，就是在线上系统里面，之前所有写库的地方，增删改操作，都除了对老库增删改，都加上对新库的增删改，同时写俩库。然后系统部署之后，新库数据差太远，用导数工具，跑起来读老库数据写新库，写的时候要根据gmt_modified这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。接着导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。

接着当数据完全一致了，就ok了，基于仅仅使用分库分表的最新代码，重新部署一次。

### 4.动态扩容缩容的分表方案是什么？

如果你分库分表之后现在这些库和表又支撑不住了，要继续扩容怎么办？可能就你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。

可以一开始上来就是32个库，每个库32个表，1024张表，根据某个id先根据32取模路由到库，再根据32取模路由到库里的表。
无论是并发支撑还是数据量支撑都没问题，每个库正常承载的写入并发量是1000，如果每个库承载1500的写并发，32 * 1500 = 48000的写并发，接近5万/s的写入并发，前面再加一个MQ，削峰，每秒写入MQ 8万条数据，每秒消费5万条数据。1024张表，假设每个表放500万数据，在MySQL里可以放50亿条数据。哪怕是要减少库的数量，就按倍数缩容就可以了，然后修改一下路由规则。

### 5.全局唯一id生成方法

1.数据库自增id：这个就是说你的系统里每次得到一个id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个id。拿到这个id之后再往对应的分库分表里去写入。这个方案的好处就是方便简单，谁都会用；缺点就是单库生成自增id，要是高并发的话，就会有瓶颈的。

2.UUID：好处就是本地生成，不好之处就是，uuid太长了，作为主键性能太差了，不适合用于主键。

3.雪花算法，一个long型的64bit，第一位不用，然后后面的41 bit作为毫秒数，他可以表示69年的时间，用10 bit作为工作机器id，工作机器可以分为机房和机器，12 bit作为序列号，就是1毫秒内第几个请求。


https://juejin.im/entry/5ba0a254e51d450e735e4a1f
