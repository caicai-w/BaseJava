## 一、一条SQL的执行过程
## 二、InnoDB体系架构
## 三、Innodb关键特性
## 四、索引
## 五、锁
## 六、分库分表

## 一、一条SQL的执行过程

### 1.建立连接

MySQL客户端/服务端通信协议是“半双工“的，这两端不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。what？tcp会给你控制吧！！

### 2.查询缓存

在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这个查询缓存在8.0之后都被删掉了，没这个功能了。

### 3.语法解析和预处理

分析器会对你的sql语法做词法分析和语法分析，会根据语法分析器的规则判断你这个输入是否满足mysql的语法。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等等。

### 4.查询优化

一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到它觉得最好的执行计划。优化器所在的工作就是在表里面有多个索引的时候，决定使用哪个索引，或者在一个语句有多表关联的时候，决定各个表的连接顺序。MySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的 `last_query_cost`的值来得到其计算当前查询的成本。

```mysql
show status like 'last_query_cost';
+-----------------+-------------+
|Variable_name    |Value        |
+-----------------+-------------+
|Last_query_cost  |6391.799000  |
+-----------------+-------------+
```

示例中的结果表示优化器认为大概需要做6391个数据页的随机查找才能完成上面的查询。这个结果是根据一些列的统计信息计算得来的，这些统计信息包括：每张表或者索引的页面个数、索引的基数、索引和数据行的长度、索引的分布情况等等。

有非常多的原因会导致MySQL选择错误的执行计划，比如统计信息不准确、不会考虑不受其控制的操作成本（用户自定义函数、存储过程）、MySQL认为的最优跟我们想的不一样（我们希望执行时间尽可能短，但MySQL值选择它认为成本小的，但成本小并不意味着执行时间短）等等。MySQL的查询优化器是一个非常复杂的部件，它使用了非常多的优化策略来生成一个最优的执行计划：

- 重新定义表的关联顺序（多张表关联查询时，并不一定按照SQL中指定的顺序进行，但有一些技巧可以指定关联顺序）
- 优化 `MIN()`和 `MAX()`函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值）
- 提前终止查询（比如：使用Limit时，查找到满足数量的结果集后会立即终止查询）

### 5.查询执行引擎

在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为 `handler API`。查询过程中的每一张表由一个 `handler`实例表示。实际上，MySQL在查询优化阶段就为每一张表创建了一个 `handler`实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。

### 6.返回结果

结果集的返回有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足①中所描述的通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。

### 7.性能优化建议

##### 1.scheme设计与数据类型设计

数据类型只要遵循**小而简单**的原则就好，越小的数据类型通常会更快，占用更少的磁盘、内存，处理时需要的CPU周期也更少。

这里总结几个可能容易理解错误的技巧：

1. 通常来说把可为 `NULL`的列改为 `NOT NULL`不会对性能提升有多少帮助，只是如果计划在列上创建索引，就应该将该列设置为 `NOT NULL`。
2. 对整数类型指定宽度，比如 `INT(11)`，没有任何卵用。 `INT`使用32位（4个字节）存储空间，那么它的表示范围已经确定，所以 `INT(1)`和 `INT(20)`对于存储和计算是相同的。
3. `UNSIGNED`表示不允许负值，大致可以使正数的上限提高一倍。比如 `TINYINT`存储范围是-128 ~ 127，而 `UNSIGNED TINYINT`存储的范围却是0 - 255。
4. 通常来讲，没有太大的必要使用 `DECIMAL`数据类型。即使是在需要存储财务数据时，仍然可以使用 `BIGINT`。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用 `BIGINT`存储。这样可以避免浮点数计算不准确和 `DECIMAL`精确计算代价高的问题。
5. `TIMESTAMP`使用4个字节存储空间， `DATETIME`使用8个字节存储空间。因而， `TIMESTAMP`只能表示1970 - 2038年，比 `DATETIME`表示的范围小得多，而且 `TIMESTAMP`的值因时区不同而不同。
6. 大表 `ALTER TABLE`非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。当然有一些奇淫技巧可以解决这个问题，有兴趣可自行查阅。

##### 2.就是索引的列参与了运算，那这个索引是不生效的。

##### 3.避免多个范围查询，比如：

```mysql
select user.* from user where login_time >'2017-04-01'and age between 18 and 30;
```

 这个查询有一个问题：它有两个范围条件，logintime列和age列，MySQL可以使用logintime列的索引或者age列的索引，但无法同时使用它们。

##### 4.覆盖索引

如果一个索引包含或者说覆盖所有需要查询的字段的值，那么就没有必要再回表查询，这就称为覆盖索引。不要select *。

##### 5.特定类型查询优化

1.优化COUNT()查询

`COUNT()`可能是被大家误解最多的函数了，它有两种不同的作用，其一是统计某个列值的数量，其二是统计行数。统计列值时，要求列值是非空的，它不会统计NULL。如果确认括号中的表达式不可能为空时，实际上就是在统计行数。最简单的就是当使用 `COUNT(*)`时，并不是我们所想象的那样扩展成所有的列，实际上，它会忽略所有的列而直接统计所有的行数。

我们最常见的误解也就在这儿，在括号内指定了一列却希望统计结果是行数，而且还常常误以为前者的性能会更好。但实际并非这样，如果要统计行数，直接使用 `COUNT(*)`，意义清晰，且性能更好。

有时候某些业务场景并不需要完全精确的 `COUNT`值，可以用近似值来代替，EXPLAIN出来的行数就是一个不错的近似值，而且执行EXPLAIN并不需要真正地去执行查询，所以成本非常低。通常来说，执行 `COUNT()`都需要扫描大量的行才能获取到精确的数据，因此很难优化，MySQL层面还能做得也就只有覆盖索引了。如果不还能解决问题，只有从架构层面解决了，比如添加汇总表，或者使用redis这样的外部缓存系统。

##### 2.优化关联查询

在大数据场景下，表与表之间通过一个冗余字段来关联，要比直接使用 `JOIN`有更好的性能。如果确实需要使用关联查询的情况下，需要特别注意的是：

- 确保 `ON`和 `USING`字句中的列上有索引。在创建索引的时候就要考虑到关联的顺序。当表A和表B用列c关联的时候，如果优化器关联的顺序是A、B，那么就不需要在A表的对应列上创建索引。没有用到的索引会带来额外的负担，一般来说，除非有其他理由，只需要在关联顺序中的第二张表的相应列上创建索引（具体原因下文分析）。
- 确保任何的 `GROUP BY`和 `ORDER BY`中的表达式只涉及到一个表中的列，这样MySQL才有可能使用索引来优化。

要理解优化关联查询的第一个技巧，就需要理解MySQL是如何执行关联查询的。当前MySQL关联执行的策略非常简单，它对任何的关联都执行**嵌套循环关联**操作，即先在一个表中循环取出单条数据，然后在嵌套循环到下一个表中寻找匹配的行，依次下去，直到找到所有表中匹配的行为为止。然后根据各个表匹配的行，返回查询中需要的各个列。

太抽象了？以上面的示例来说明，比如有这样的一个查询：

```

```

假设MySQL按照查询中的关联顺序A、B来进行关联操作，那么可以用下面的伪代码表示MySQL如何完成这个查询：

```

```

可以看到，最外层的查询是根据 `A.xx`列来查询的， `A.c`上如果有索引的话，整个关联查询也不会使用。再看内层的查询，很明显 `B.c`上如果有索引的话，能够加速查询，因此只需要在关联顺序中的第二张表的相应列上创建索引即可。

##### 优化LIMIT分页

当需要分页操作时，通常会使用 `LIMIT`加上偏移量的办法实现，同时加上合适的 `ORDER BY`字句。如果有对应的索引，通常效率会不错，否则，MySQL需要做大量的文件排序操作。

一个常见的问题是当偏移量非常大的时候，比如： `LIMIT1000020`这样的查询，MySQL需要查询10020条记录然后只返回20条记录，前面的10000条都将被抛弃，这样的代价非常高。

优化这种查询一个最简单的办法就是尽可能的使用覆盖索引扫描，而不是查询所有的列。然后根据需要做一次关联查询再返回所有的列。对于偏移量很大时，这样做的效率会提升非常大。考虑下面的查询：

```

```

如果这张表非常大，那么这个查询最好改成下面的样子：

```

```

这里的延迟关联将大大提升查询效率，让MySQL扫描尽可能少的页面，获取需要访问的记录后在根据关联列回原表查询所需要的列。

有时候如果可以使用书签记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用 `OFFSET`，比如下面的查询：

```

```

其他优化的办法还包括使用预先计算的汇总表，或者关联到一个冗余表，冗余表中只包含主键列和需要做排序的列。

##### 优化UNION

MySQL处理 `UNION`的策略是先创建临时表，然后再把各个查询结果插入到临时表中，最后再来做查询。因此很多优化策略在 `UNION`查询中都没有办法很好的时候。经常需要手动将 `WHERE`、 `LIMIT`、 `ORDER BY`等字句“下推”到各个子查询中，以便优化器可以充分利用这些条件先优化。

除非确实需要服务器去重，否则就一定要使用 `UNION ALL`，如果没有 `ALL`关键字，MySQL会给临时表加上 `DISTINCT`选项，这会导致整个临时表的数据做唯一性检查，这样做的代价非常高。当然即使使用ALL关键字，MySQL总是将结果放入临时表，然后再读出，再返回给客户端。虽然很多时候没有这个必要，比如有时候可以直接把每个子查询的结果返回给客户端。

## 二、InnoDB体系架构

后台线程、缓冲池

#### 1.后台线程

多线程模型，用来处理不同的任务。

##### （1）Master Thread：把缓冲池数据异步刷新到磁盘，包括脏页、合并插入缓冲、undo页回收。

##### （2）IO Thread

innodb使用大量AIO处理写IO请求。IO Thread的作用就是负责这些IO请求的回调。

##### （3）Purge Thread

事物提交后，使用的undolog可能不再需要，需要purge 回收已经分配的undo页。

##### （4）Page cleaner Thread

脏页的刷盘都放到这个线程了。

#### 2.内存

##### （1）缓冲池

Innodb存储是基于磁盘，存储按照页进行管理，所以需要缓冲池来中和一下cpu和磁盘速度，在数据库读页的时候，先从磁盘读到缓冲池，下一次读的时候先看缓冲池有没有。对数据修改时，也修改缓冲池里的（如果没有命中，是先读取出来到缓存？再改？还是直接刷磁盘？），再以一定的频率刷回磁盘，但它也不是你每次改了缓冲池之后就一定会触发刷盘操作，它使用了一种**检查点**机制。

###### 缓冲池里的数据有什么呢？

有索引页，数据页，undo页，插入缓存，自适应哈希，锁信息，数据字典等，不能任务缓冲池只缓存数据页和索引页，只是他们占很大一部分而已。
毕竟缓存有限的，那么当容量不够了怎么办呢？一般情况下缓存里的数据都是通过LRU算法管理，Innodb在LRU基础上做了优化，它加入了midPoint，新读取到的页，虽然是最新访问的，但并不直接插到头部，而是放到LRU列表的midPoint位置，在LRU列表长度的5/8处，midPoint之后的都叫old列表，之前的都叫new 列表，可以认为new列表都是热点数据。
为什么不采用朴素LRU？比如你做了一个扫描全表的操作，这些操作其实这是在这一次用到了，如果你把真正的热点数据都替换掉了，下次就还要找磁盘。

LRU是来管理页的一种方式，数据刚启动的时候肯定是没有什么热点数据的，LRU是空的，页空间都是Free在管理，当来了新的页先看free有没有空间，如果没有就用LRU替换了。一般来说缓冲池的命中应该在95%以上，如果达不到可能就是全表扫描让LRU污染（真正的热点数据被搞没了）。

LRU List里面的页被修改之后，称为脏页，缓冲池里的页和磁盘里的不一致了，这时候这个页也会挂到Flush List上，这两个list不冲突。

缓冲池允许有多个，页根据哈希值平均分配到不同的缓冲池实例。（当我查找页数据或者索引时，根据一个数据怎么确定是哪个缓冲池？还是说要遍历缓冲池。）

缓冲池里还有redo log缓冲，和额外的缓冲空间。
Innodb首先把redolog放在缓冲池，然后按照一定的频率刷到重做日志文件。redolog缓冲不需要很大，只要能存下1s的就可以，在下面三种情况时就把redolog刷到磁盘日志文件：
1.Master Thread每1s把重做日志缓冲刷到重做日志文件
2.当有新事务提交的时候刷。
3.当重做缓冲池剩余空间小于1/2时刷。

##### （2）checkPoint

如果你把数据写到缓存之后掉电了，这个修改要怎么同步给磁盘？
事务数据库系统普遍采用Write Ahead Log 策略，当事务提交时：**先写重做日志，再修改页。**
检查点机制的作用是：缩短数据库恢复时间 | 缓存池不够用时，把脏页刷新到磁盘 | 重做日志不可用时，刷新脏页。
当数据库宕机，checkPonit之前的都是好的，需要对checkPonit之后的数据进行恢复。另外当缓冲池不够用时，LRU换掉的如果是脏页，也会强制执行checkPoint。
那么checkPoint在什么时候产生？但凡是重做日志还有能用的，要强制产生checkPoint，将缓冲池中的页至少刷新到重做日志。

InnoDB有两种checkPoint：
sharp checkPoint（默认的工作方式）
fuzzy checkPoint
sharp checkPoint是在数据库关闭时把所有脏页刷到磁盘，但是数据库在运行的时候肯定不能这样。
Fuzzy是只刷新一部分，InnoDB引擎使用这种刷新方式，下面是发生fuzzy checkPoint的几种方式：
1）Master Thread checkPoint，对master thread发生的checkPoint差不多以每1s或者每10s的速度从缓冲池的脏页列表中刷一定比例的页到磁盘。
2）FLUSH_LRU_List

##### （3）mysql日志

现在只说说mysql 的日志redolog 和 binlog ，redolog 是独属于 innodb 的日志，binlog 则是属于 server 层的日志。

##### redolog是什么？

redo log包括两部分：一是内存中的日志缓冲(redo log buffer)，该部分日志是易失性的；二是磁盘上的重做日志文件(redo log file)，该部分日志是持久的。
在概念上，innodb通过force log at commit机制实现事务的持久性，即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化。
为了确保每次日志都能写入到事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作(即fsync()系统调用)。因为MySQL是工作在用户空间的，MySQL的log buffer处于用户空间的内存中。要写入到磁盘上的log file中，中间还要经过操作系统内核空间的os buffer，调用fsync()的作用就是将os buffer中的日志刷到磁盘上的log file中。

redolog 是物理日志，记录的是某个表的数据做了哪些修改，redolog 是固定大小的，也就是说后面的日志会覆盖前面的日志。

binlog 又称作归档日志，它记录了对 MySQL 数据库执行更改的所有操作，但是不包括 SELECT 和 SHOW 这类操作。binlog 是逻辑日志，记录的是某个表执行了哪些操作。binlog 是追加形式的写入日志，后面的日志不会被前面的覆盖。

###### 3.1 数据更新过程

我们执行一个更新操作是这样的：读取对应的数据到内存—>更新数据—>写 redolog 日志—> redolog 状态为 prepare —>写 binlog 日志—>提交事务—> redolog 状态为 commit ，数据正式写入日志文件。我们发现 redolog 的提交方式为“两段式提交”，这样做的目的是为了数据恢复的时候确保数据恢复的准确性，因为数据恢复是通过备份的 binlog 来完成的，所以要确保 redolog 要和 binlog 一致。
前面说宕机有redolog，现在又说用binlog，到底用啥？
那么，binlog和redolog有什么区别？

## 三、Innodb关键特性

插入缓冲、两次写、自适应哈希索引、异步IO、刷新邻接页

#### 1.插入缓冲

InnoDB中，主键是行唯一的标志，通常应用程序中记录的插入顺序是按照主键的递增顺序进行插入。因此插入聚集索引都是顺序的，不用在磁盘上随机读。
但更多时候你需要去建一些非聚集索引去辅助查询，因为B+树叶子的数据根据主键顺序存放，所以可能用你建的索引去插入的时候就是离散的了。

所以对于非聚集索引中数据的的插入和更新，如果索引页在缓冲池就直接插入，如果缓冲池没有，就放到一个insert buffer对象中，再以一定的频率把insert buffer和辅助索引的叶子节点merge，这时通常可以把多个merge合并成一个操作。要想使用insert buffer需要满足两个条件：索引是辅助索引，索引不要求value唯一（如果要求唯一，那还要去索引页上找是不是唯一的，没法用）。

Change buffer是insert buffer的升级，可以分成：insert buffer，delete buffer，purge buffer，可以对insert、delete和update都进行缓冲。和insert一样change buffer适用的对象还是不唯一的辅助索引。

比如update操作，Delete buffer对应update的第一个操作，purge buffer对应update的第二个操作，即将真正的记录删除。

#### 2.两次写（double write）

部分写失效情况：如果在从缓冲中的数据页写到磁盘时，写到一半挂了。这样页就被损坏了，也许会想到用重做日志去恢复，但redo log存的是对页的物理操作，页已经坏了没办法恢复？？所以需要一个页副本，当写失效发生，先还原受损的页，再进行重做。
在对缓冲池的脏页进行刷新时，并不直接写磁盘，而是先把脏页复制到内存中的double write buffer。

#### 3.自适应哈希

就是Innodb会监控B+索引，如果它觉得给你建和自适应哈希会让查询速度更快就会给你建。自适应hash是根据缓冲池的B+树来构造，而且不要求对整张表建立hash索引，它会自动给某些热点页建立hash索引。
自适应hash有一个要求：对这个页的连续访问模式必须是一样的，例如对于（a，b）这样的联合索引页，访问方式可以是：
where a = xxx 或者 where a = xxx and b = xxx
必须是其中一种，不能两种交替，而且要以该模式访问100次，页通过该模式访问了N次，N=页中记录*1/16。

#### 4.异步IO（AIO）

为了提高性能，当前数据库都采用异步IO，用户发一个IO请求之后可以再发送一个IO请求，而且它可以把多个IO请求优化成一个，比如发了一个（8，6），（8，7），（8，8），AIO判断这些页是连续的，就可以发一个读（8，6）的IO。

#### 5.刷新邻接页

就是把脏页刷到磁盘时，会检查页所在的区还有没有其他脏页，如果有就一起刷回去。好处就是AIO可以把多个IO合成一个。

## 四、索引



索引做的事情：查找和排序。mysql支持的常见索引：B+，全文、hash

### 1.B+树索引

B+树索引可以分为聚簇索引和非聚簇索引。不管是聚簇还是非聚簇，内部都是B+树，即高度平衡的，叶子存放着所有的数据，聚簇和非聚簇不同的是叶子节点存放的是否是一整行的数据。
聚簇索引就是按照每张表的主键构造一颗B+，叶子节点存放整行数据，每个数据页通过双向链表连接。聚簇索引的存储在物理上并不是连续的，他们一是通过页之间的双向链表，二是页中的记录也通过双向链表维护。聚簇的好处就是对于范围查找和对于主键的排序查找非常快。
辅助索引（非聚簇索引），叶子并不包含行的全部记录，它除了存储辅助索引的value，每个叶子节点中的索引中还包含一个书签，书签指明去哪里找索引对应的行数据，也就是聚簇索引的健。一张表可以有多个辅助索引。（尽量不要用select *，避免回表）

### 2.不适合建B+的情况

关于什么时候适合➕B+索引，不是所有要查询的字段都适合，比如对于性别这种字段，就两个值，这样就完全没有必要，B+适合高选择性字段。Cardinality表示索引中不重复记录的预估值，应该让Cardinality/row尽可能接近1。
这个Cardinality你用show index的时候可以显示出来，但是这只是一个预估的值，他也不是每次修改索引都会更新的，所以你可以选择在数据库空闲的时间做analyze table操作，为了让优化器更好的为你工作，因为可能Cardinality非常小，查询优化器就不愿意走这个索引了。

B+索引叶子节点因为是链表链起来的（叶子节点里面的行数据也是链表链起来的），所以没办法做二分，那么，每个叶子节点有个page directionry，它是专门用来给叶子节点做二分的。

⚠️B+索引并不能找到一个给定健值所在的具体行，B+索引能找到的只是被查找数据所在的页，然后数据库通过把页读到内存，再在内存中进行查找，最后得到要查找的数据。

### 3.B+索引的使用

**（1）.联合索引**
联合索引也是一棵B+，联合索引除了特定查询需要，第二个好处是在某些场景下可以当作排序，比如我们给（a，b）建立了联合索引，所以下列语句优化器就会选择联合索引,因为b是在每一段a中排序的
select  ... from table where a=xxx order by b;
同样，对于（a，b，c）下面语句同样可以得到结果：
select ... from table where a=xxx order by b；
select ... from table where a=xxx and b =yyy order by c；
但是
select ... from table where a=xxx order by c不行，因为在a里面c不是排序的。
**（2）.覆盖索引**
就是从辅助索引就可以查到数据，就不需要再走聚簇索引了。而且还有一种 情况是比如有个表table。
select count(*) from table。如果这个表有辅助索引是会通过辅助索引去做count的，因为辅助索引小，肯定IO少。
**（3）.优化器选择不使用索引的情况**
有时候在进行查询的时候，直接走B+索引，也就是全表的一个扫描，多发生的范围查询和join连接。
比如用select * 对订单id进行某个范围的查询，如果走辅助索引还要去聚簇索引读取整行数据，这种情况就会直接使用聚簇索引。另外，索引查询优化器会帮我们做选择，但它去计算选择哪个索引更好的时候本身也会浪费时间，可以用use index强制走哪个索引。
**（4）.MRR优化**
Multi-range-read优化的目的就是减少磁盘的随机访问，把随机访问转换成较为顺序的访问，减少IO。
对于range类型的查询，使用mrr的好处：
在查找辅助索引时，首先根据得到的查询结果，按照主键进行排序，按照主键的顺序进行书签查找。（比如上个例子select * ，我用辅助索引，那要根据主键再去查聚簇索引，所以这个时候，如果给主键索引排个序，可能会减少IO），
减少缓冲池中页被替换的次数，
批量处理对键值的查询。

对于范围查询和join，mrr的优化方式是：
将查询得到的辅助索引放到一个缓存里，这时缓存里的辅助索引是键值排序的；将缓存中的键值用rowId进行排序，根据rowId的排序顺序来访问实际的数据文件。

##### 1.2 Fast Index Creation

在MySQL5.5版本之前，一个很糟糕的创建和删除索引的方式是：
当你要对索引进行DDL操作，会先创建一张临时表，然后把原表中的数据倒入进去，再把原表删除然后把临时表重命名为原来的表。
那么，如果是对一张大表的索引进行这样的操作，是非常耗时的，这段时间数据库是不对外提供服务的。InnoDB1.0之后的版本支持FIC，在创建辅助索引的时候可以对表加个S锁就行，但是这个时间段内也是不能修改的，只能读。

##### 1.3 Cardinality

前面也说了这是查询优化器会重要参考的一个参数。但是Cardinality不是实时更新的，比如一个数据量非常大的表，不可能在每次更新索引的时候都去更新Cardinality，那么InnoDB存储引擎对Cardinality的更新策略为：
1.表中1/16的数据已经发生过变化
2.表中发生变化的次数 > 2000000000
那么，Cardinality到底是怎么统计出来的呢？
1.取B+叶子节点的数量
2.随机拿8个叶子节点统计每个叶不同的记录个数。
3.然后（P1+...+P8）*A/8
这个数据只是采样得到的，所以可能你数据没变每一次算出来的结果也不同。

### 4.哈希索引

O (1)时间的算法，自适应hash不是DBA能干预的，hash只适用于=的情况，范围就不行了。能O(1)时间查找，但只能精确查找，不能范围查找。InnoDB存储引擎有个功能叫自适应哈希，当某个索引值被使用的非常频繁，会在B+之上再建立一个哈希索引。

### 5.全文索引

B+树索引也可以根据索引的前缀查找，比如
select * from blog where content like ‘xxx%’，但很多情况是需要‘%xxxx%’。MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。

### 6.倒排索引

全文索引使用倒排来实现，倒排是一种结构，和B+索引一样。
Innodb支持全文检索，并且是full inverted index的形式，就是单词对应的不仅有文档id，还显示在文档中第几个单词（DocumentId，Position）看做一个ilist，所以在全文检索的表中有两个列，一个是word字段，一个是ilist字段，并且word字段上有索引。
倒排索引需要把word放在一张表中，这个表成为辅助表，在Innodb引擎中，为了提高全文检索并行性能，共有6张辅助表。辅助表是持久表，放在磁盘上，然而Innodb存储引擎的全文索引中。
一张表只能有一个全文检索的索引。

### 7、MySQL采用B+树的原因

1.平均查找次数少。平衡树查找的时间和树的高度有关LogdN，d是每个节点的出度，红黑树的出度是2，但是B+树的出度很大，明显红黑树更高查找次数多。
2.可以减少IO操作。
数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I/O 就能完全载入一个节点。每次在一个节点中查询减少了IO的次数。
其他：为了减少磁盘 I/O 操作，磁盘不是严格按需读取，它每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，只需要很短的旋转时间，速度会非常快。

操作系统一般将内存和磁盘分割成固定大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。并且可以利用预读特性，相邻的节点也能够被预先载入。



### 8、索引优化

1.在查询的时候，索引列不能是表达式的一部分，否则无法使用。

```
SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;
```

2.在多个列查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引.

```
SELECT film_id, actor_ id FROM sakila.film_actor
WHERE actor_id = 1 AND film_id = 1;
```

3.让选择性最强的索引列放在前面。
索引选择性强就是说不重复的索引值多。
4.对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。对于前缀长度的选取需要根据索引选择性来确定。
5.覆盖索引：索引包含所有需要查询的字段的值。
具有以下优点：
索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。
对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。

### 9、索引的优点

减少了服数据的查找次数。
帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表）。
将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。

### 10、索引使用的条件、适合和不适合

对于非常小的表、大部分情况下简单的全表描比建立索引更好；经常增删改的表也不适合建索引，重复数据非常多也不适合建索引。
适合的情况：主键适合做唯一索引，频繁作为查询条件的字段，外键也可以做索引。查询中
对于中到大型的表，索引就非常有效；
查询中排序的字段，排序字段如果通过索引访问会大大提高查询速度。
但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。

### 11.索引优化策略

1.最左前缀匹配，主键外键一定要建索引，对where，on，group by，order by中出现的列使用索引。

2.使用高效选择性字段当索引，索引列不参与计算，

## 五、锁

lock和latch
lock的对象是事务，用来锁定数据库中的对象，如表、页、行。并且一般lock的对象仅在事务commit或rollback后进行释放（不同隔离级别可能不一样）。

### 0.Innodb锁的类型

InnoDB引擎实现两种标准的行级锁：
共享锁，允许事务读一行数据
排他锁，允许事务删除或更新一行数据
Innodb支持多粒度锁定，允许行级锁和表级锁同时存在，为了支持多粒度锁定，Innodb还支持意向锁，就是事务希望在更细粒度加锁。意向锁可以理解为表锁，比如你想给记录里的r加锁，那你需要先给数据库A，表1，和页加上意向锁IX，最后给r上x锁，如果粗粒度的锁不成功，那么就要等上一个表锁完成。
Innodb支持的两种意向锁：
意向共享锁：事务想要获得一张表中某几行的共享锁
意向排他锁：事务想要获得一张表中某几行的排他锁。
因为Innodb支持的是行级锁，其实意向锁其实不会阻塞全表扫意外的任何请求。
![image.png](https://upload-images.jianshu.io/upload_images/12328609-a07e7b149ed18f85.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- 什么是一致性非锁定读，MVCC？
- 什么是一致性锁定读
- 行锁的三种算法

### 1.什么是一致性非锁定读？

一致性非锁定读是指InnoDB存储引擎通过行多版本控制的方式来读取当前执行时间数据库中行的数据，如果读取的行正在进行delete/update操作，读取不回因为有排他的行锁就等待，而是去读取行的快照数据。
快照数据是该行之前版本的数据，实现是通过undo字段来完成。这是InnoDB默认的读取方式，但是在不同的数据隔离级别下，读取的方式不同，并不是在每个事务隔离级别下都是采用非锁定的一致性读，即使采用了，对于数据快照的定义也不同。
那么，快照数据其实就是当前行的数据之前的历史版本，每行记录可能有多个版本，一行可能有不止一个快照数据，一般称这种技术为行多版本技术，由此带来的并发控制，叫做多版本并发控制（MVCC）。
在事务隔离级别：读提交、可重复读中，虽然都使用一致性非锁定读，但是对于数据快照的定义是不一样的，在读提交中，每次读取的是行的最新一份快照数据，比如你在一个读取事务里面，读了两次，可能中间这个记录被删掉了，那你第二次读的时候这个数据就不存在了。但是，可重复读的话，它读取的是读取这个事务开始的行数据版本，如果这个读取事务没有结束，中间有人来更新了删掉了，但再次读取的话还是和第一次读取的数值一样，注意是同一个读事务。

### 2.什么是一致性锁定读？

某些情况下，需要强制读取的一致性，就需要加锁了
select  ...  for update对读取的行记录加一个X锁
select  ...  lock in share mode 对读取的行记录加S锁

### 3.行锁的三种算法

**1、Record Lock 单个行记录上的锁**
锁的是索引，如果这行没索引，那就会用隐式的主键进行锁定，
**2、间隙锁**
锁定一个范围，但不包含记录本身。
**3、Next-Key Lock**
间隙锁➕单个行记录上的锁两者结合，锁定一个范围，并且锁定记录本身。InnoDB都是采用这种算法锁定。

```
如果事务T1已经通过Next-Key Lock锁定了下面范围：
(10,11]、(11,13]
当插入新的记录12时，锁定范围会变成下面：
(10,11]、(11,12]、(12,13]
```

但是，如果查询的索引有唯一属性，就会把next-key-locks降级，变成Record Lock，仅锁住索引本身，而不是范围，这也只是在select * from t where
a = 5的情况，只能是在判断相等的时候。
但如果索引没有唯一约束，而查询又是等于的情况，比如select * from t where
a = 5，那么不仅会锁上a=5，如果a的值除了5还有1和7，那么同时也会锁上(1,5),(5,7)这两个范围。

##### 3.1 RR隔离级别怎么避免的幻读

比如你 select * from table where a > 2 for update，那锁住的不仅是大于2的每一行，而是对于2到正无穷这个范围加X锁，在这个范围内的任何插入都是不允许的，避免幻读。

[https://juejin.im/post/5d5671a2e51d45620821cea7](https://juejin.im/post/5d5671a2e51d45620821cea7)

## 六、分库分表

### 1.为什么要分库分表？

一个是单机MySQL QPS太高，第二个就是数据亮太大。

对于qps太高，你可以把数据分散到不同的库里面去，每个库分担一部分请求。第二个就是数据量太大，比如单表数据量上千万了，你就可以把一张表的拆成多个表。

### 2.分库分表的方式

首先，分库和分表是不同的概念，分表就是把一张表的数据拆到多个表里，因为innodb里的一颗B+树大概能存两千万的数据，而且数据量太大一条查询语句已经会执行的非常慢了。那对于分表，你可以把一张表的数据拆分到多个表里面去，比如，给司机分了10张表，可以用司机id%10来算这个司机id存储在哪张表里。这种拆分叫水平拆分，所有表的字段是一样的，只是数据不一样，所有的数据加起来才是完整的数据。这个分好的表也可以放到不同的库里面去，用多个库扛住更高的并发，也能实现存储的扩容。

还有一种拆分就是，垂直拆分，比如有一些字段是查询频率很高的字段，有些字段没人查，那可以把查询频率高的字段单拿出来做一张表，查询频率低的字段做一张表。这样的一个好处是，因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存保存更多的行。这种拆分一般在表层面做的更多一些。

那如果你拆完之后，一个库的大小还是不够，就可以把这些放到其他库里。或者是单机qps不够，那也可以当到多个库里面去。那这个分库的方式有两种，一种是range，就是每个库一段连续的数据，比如按照时间的范围来，但是这种方式比较容易产生热点问题，就是大部分请求都去冲着最新的数据去的，另一种是按照某个字段做hash，这个比较常用，比如说比如用司机hash(driverID)%库的数量，hash(driverID)%表的数量，这样去找在哪个表上。
优缺点：
range来分，好处在于说，后面扩容的时候，就很容易，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。hash分法，好处在于说，可以平均分配没给库的数据量和请求压力；坏处在于扩容起来比较麻烦，会有一个数据迁移过程。

### 3.怎么把单库单表迁移到分库分表上去？

假设，现在有一个单表600万数据的表，你现在把他分了三个库，每个库四个表，单表50万。怎么迁移？
一般来说就是双写，就是在线上系统里面，之前所有写库的地方，增删改操作，都除了对老库增删改，都加上对新库的增删改，同时写俩库。然后系统部署之后，新库数据差太远，用导数工具，跑起来读老库数据写新库，写的时候要根据gmt_modified这类字段判断这条数据最后修改的时间，除非是读出来的数据在新库里没有，或者是比新库的数据新才会写。接着导完一轮之后，有可能数据还是存在不一致，那么就程序自动做一轮校验，比对新老库每个表的每条数据，接着如果有不一样的，就针对那些不一样的，从老库读数据再次写。反复循环，直到两个库每个表的数据都完全一致为止。

接着当数据完全一致了，就ok了，基于仅仅使用分库分表的最新代码，重新部署一次。

### 4.动态扩容缩容的分表方案是什么？

如果你分库分表之后现在这些库和表又支撑不住了，要继续扩容怎么办？可能就你的每个库的容量又快满了，或者是你的表数据量又太大了，也可能是你每个库的写并发太高了，你得继续扩容。

可以一开始上来就是32个库，每个库32个表，1024张表，根据某个id先根据32取模路由到库，再根据32取模路由到库里的表。
无论是并发支撑还是数据量支撑都没问题，每个库正常承载的写入并发量是1000，如果每个库承载1500的写并发，32 * 1500 = 48000的写并发，接近5万/s的写入并发，前面再加一个MQ，削峰，每秒写入MQ 8万条数据，每秒消费5万条数据。1024张表，假设每个表放500万数据，在MySQL里可以放50亿条数据。哪怕是要减少库的数量，就按倍数缩容就可以了，然后修改一下路由规则。

### 5.全局唯一id生成方法

1.数据库自增id：这个就是说你的系统里每次得到一个id，都是往一个库的一个表里插入一条没什么业务含义的数据，然后获取一个数据库自增的一个id。拿到这个id之后再往对应的分库分表里去写入。这个方案的好处就是方便简单，谁都会用；缺点就是单库生成自增id，要是高并发的话，就会有瓶颈的。

2.UUID：好处就是本地生成，不好之处就是，uuid太长了，作为主键性能太差了，不适合用于主键。

3.雪花算法，一个long型的64bit，第一位不用，然后后面的41 bit作为毫秒数，他可以表示69年的时间，用10 bit作为工作机器id，工作机器可以分为机房和机器，12 bit作为序列号，就是1毫秒内第几个请求。



