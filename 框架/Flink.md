# 1.流式处理

### 1.1流式处理框架比较

Spark Streeaming：他其实是微批次处理，秒级别延迟，它相比较Storm，吞吐量大而且可以保证精确一次性。如果用kafka和Spark对接，那么kafka有几个分区，对应spark就有几个分区，会去对应的分区拉数据，假如每5s一个时间窗口，那每拉5s就组成一个rdd送去计算。

Storm：延迟毫秒级，但是因为延迟低，所以吞吐量不高，不能保证精确一次性，大部分框架都只能保证至少一次，精确一次性是只有一次，消息不重复也不丢。所以Storm又出了一个Trident，是对storm的延伸，可以做到精确一次，但延迟方面付出了代价。 

Flink：他做到了精确一次性，高吞吐，保持精确一次性。他有把数据放到内存的计算速度，数据也可以任意规模。

批处理的特点是有界、持久、大量，适合处理离线数据，Hadoop就是纯粹的批处理，而流式处理特点是无界、实时，不需要对整个数据集进行操作。storm是只能流处理，spark既可以批又可以流，但是它是不同的技术框架，分别实现的，Flink是不管批还是流都不区分，它把批处理当作特殊的流处理。

### 1.2流式的理解

流式计算会根据收到的结果不断更新并且永远都不会完成。如果不要求在

例子：
通过追踪网站的三个访问者的活动，对于访问者来说，可能半小时内访问3次，也可能10分钟访问20次，活动是不连续的，在访问的时间段内，每次的访问数据都会被收集起来。

发生故障后保持准确：
若想使计算保持准确，要根据计算状态，如果计算框架本身不能做到，连续的流处理很难跟踪计算状态，因为计算过程没有终点，实际上，对状态的更新是持续进行的，
Flink用的技术叫做检查点，checkpoint，在每个检查点，系统都会记录中间计算状态，从而在故障发生时准确的重置，这一方法使系统以低开销的方式拥有容错能力，当一切正常时，检查点机制对系统影响很小。

Flink是怎么做到实时和容错的？

乱序事件由Flink自行处理，此外，如果应用程序代码有过改动，只需要重播kafka主题，即可重播应用程序。

### 1.3Flink的架构

Flink有个runTime的概念，它既可以是本地也可以是集群，DataStream API针对流处理，DataSet API针对批处理，你可以在一套程序里同时使用这两个。

#### 1.3.1 JobManager 和 TaskManager

JobManager对应master，是个jvm进程，用于协调分布式执行，他们来调用task。

TaskManager对应worker，用于执行一个dataflow的task、数据缓冲和data stream的交换，。

### 1.4精确一次性是如何做的？

使用检查点，在出现故障时将系统重置到正确状态。

# 2.时间概念

事件时间Event Time，即事件实际发生的时间，就是你数据本身携带的时间。
处理时间，即事件被处理的时间。
还有一个数据进入Flink的时间。

# 3.滚动窗口、滑动窗口、计数窗口、会话窗口

Flink的数据你可以想象成所有数据是在一个管道里面，每条数据是一个event，当我要对数据进行一些聚合等操作时候，管道内的数据是个没有边界的流式概念，你不能对一个无界的数据做聚合，所以就有了窗口的概念，每次都只在这个窗口里面的数据计算。

## 3.1窗口的类型

窗口可以分两种：一种是按照时间（时间就是每隔10s就算是一个窗口，不管你来多少），一种是按照数据的大小（比如我设置这个窗口就是只要10条）。这两种又可以根据实现类型分成三类：滚动、滑动，还有时间窗口独有的会话窗口。

### 3.1.1滚动窗口

滚动窗口：比如设置1min滚动窗口求和，就是收集1min的数值，在1min结束时输出总和，每隔1min切一次，窗口和窗口之间不重叠。

### 3.1.2 滑动窗口

滑动窗口：1min滑动窗口计算最近1min的数值总和，但每半分钟滑动一次并输出结果。要设置滑动大小和窗口大小，如果你的滑动比滚动窗口大，就不会重叠，他这个窗口是允许有重复的。
Flink中滚动窗口和滑动窗口的设置：
 stream.timeWindow(Time.minutes(1))
 stream.timeWindow(Time.minutes(1), Time.seconds(30))

计数窗口的分组依据不再是时间戳，也是元素的数量。上面说的滑动窗口和滚动窗口也可以解释为4个元素组成的计数窗口，并且每两个元素滑动一次，滚动和滑动的计数窗口可以定义为：
 stream.countWindow(4)
 stream.countWindow(4, 2)
⚠️ countWindow是指Key的数量达到count才会触发countWindow的执行。虽然计数窗口有用，但不如时间窗口严谨。因为时间窗口总会关闭。而计数窗口的话，如果是100，但某个key对应的元素永远达不到100，那么窗口就永远都不会关闭，当然也可以用时间窗口来触发超时。

### 3.1.3会话窗口

会话窗口指的是活动阶段，前后都是非活动阶段，比如用户与网站进行一系列交互之后，关闭浏览器或者不再交互，会话需要有自己的处理机制，因为它们通常没有固定的持续时间(有些 30 秒就结 束了，有些则长达一小时)，或者没有固定的交互次数(有些可能是 3 次点 击后购买，另一些可能是 40 次点击却没有购买)。Flink是唯一支持会话窗口的开源流处理器。

在Flink中，会话窗口由超时间设定，即希望等待多久才认为会话已经结束，比如，以下为用户处于非活动状态5min，则认为会话结束。也就是，如果上一条数据和下一条数据超过5min了，那认为前面是一窗口数据，后面是另一窗口数据。
 stream.window(SessionWindows.withGap(Time.minutes(5))

## 3.2窗口的实现

在Flink内部，所有类型的窗口都由同一种机制实现，虽然实现细节对于普通用户并不重要，但要注意：
开窗机制与检查点机制完全分离。窗口完全可以没有"时长"。

# 4.触发器

触发器生成控制结果的时间，即合适聚合窗口内容并把结果返回给用户，每一个默认窗口都有一个触发器。

# 5.时空穿梭

时空穿梭意味着将数据倒流回至过去某个时间，重新启动处理程序直到处理到当前时间为止。
若要按照时间回溯并正确的重新处理数据，流处理器必须支持事件事件，如果窗口的设定是根据系统时间而不是时间戳，那么每次运行同样的程序，都会得到不同的结果

# 6.水印

waterMark的存在主要就是面对乱序的情况，比如我设置的按照eventTime 3min触发，但是如果这3min的数据里面有一条丢了，那我总不能无限期的等下去吧，总要有个机制来保证即便这3min窗口有些数据没到达，也得触发，水印就是这个效果。

比如，我现在的窗口是0s-5s，我要等着eventTime是0到5的数据，我设置了水位线是2s，也就是当eventTime是7s的数据到达的时候，0-5就会被触发，不管来齐了没有。可以把watermark理解为一个延迟触发机制。如果7第一个先来了，那0—5这个窗口就没了相当于，因为里面没数据，他也不会执行。

每次来一个数据都看看这个能把哪个窗口触发了，就这样。只要窗口没触发，数据来了都会到它该去的窗口。

可以把窗口想象成，当你程序已开启，那些窗口都是已经划分好的，数据自己就会跑到已经划分好的窗口里面去，当触发条件到达了，就会触发，如果来晚了没窗口可以去，就被丢掉了。

# 7.有状态的计算

流式计算分为有状态和无状态。无状态流处理与有状态流处理的区别：无状态流处理就是不记录之前的，之前不管是什么都和这次无关，但是有状态的会记录之前的。我做的那个明显是有状态的计算。



## 8.项目实践

其实这个就是想要把判定超速这个能力给其他业务方去用，我们的超速计算逻辑都是基于端上上报的速度，如果报上来的速度不准，那算出来超速也不准，所以这个就是通过obd设备报上来的的速度数据，和端上报上的数据对比，看看有多大的差别，obd设备报的就是车的表盘显示的速度。

设置使用eventTime，也就是事件本身带有的时间。

数据源是mq，接的集团内部的ddmq，第一步就是把两个数据源的数据从JSON转成类。

第二步设置水位线，水位线odb mq设置为30s，也就是每个时间窗口endTime 30s后的任意一个数据到达的时候会触发，允许一个时间窗口中的数据来晚了30s。不是非要卡endTime+30s。而且obd数据1s有三个，所以会有三个时间戳一样的数据，一样flink会把它放在一个时间窗里面。

端上mq数据水位线我设置了9min，应该没这个必要，6min应该可以了。

第三步，因为obd数据是1s有三个，所以会有相同时间戳的数据有三个，需要把这些数据处理一下，所以设置了1s的时间窗口，允许延迟30s。端上数据同理。

第四步，join，在join之前，都是两个不相干的流。



