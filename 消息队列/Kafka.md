* 1.Kafka高可用怎么做的？
* 2.Kafka消息不重复怎么做的？如何保证消息消费时的幂等性？
* 3.Kakfa如何保证数据不丢失？
* 4.mq如何保证顺序消费？
* 5.消息积压怎么办？
* 6.Kafka为什么快？

### 1.Kafka高可用怎么做的
kafka一个最基本的架构认识：多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。
这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。

kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。

如果某个broker宕机了，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。

写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）
消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。

### 2.Kafka如何保证消息不重复？如果保证消息消费时的幂等性？
mq都有可能会出现消费重复消费的问题，幂等性是要自己去做的。

kafka有offset，就是每个消息写进去，都有一个offset代表他的序号，consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交到zk，代表我已经消费过了，但是比如我刚消费完，还没提交了就挂了，下次再去zk拉offset的时候就要重复消费了。

怎么保证消息队列消费的幂等性？
其实还是得结合业务来思考：
（1）比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，update一下
（2）比如你是写redis，那没问题了，反正每次都是set，天然幂等性
（3）比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。

还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，因为有唯一键约束，所以重复数据只会插入报错，不会导致数据库中出现脏数据。

### 3.Kafka会数据丢失吗？消息的可靠性传输？
这个丢数据，mq一般分为两种，要么是mq自己弄丢了，要么是我们消费的时候弄丢了。

1）kafka消费端弄丢了数据
唯一可能导致消费者弄丢数据的情况，就是你消费到了这个消息，消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢了。

kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。

2）kafka弄丢了数据

这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。要是此时其他的follower刚好还有些数据没有同步，选举某个follower成leader之后这就丢了一些数据。

所以此时一般是要求起码设置如下4个参数：
给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本

在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系

在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了

在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了

我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失。

3）生产者会不会弄丢数据
如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

### 4.Kafka的顺序消费问题
kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可。

### 5.消息积压怎么办？
你的消费端出了问题不消费了，或者消费的极其极其慢这个时候怎么办？

所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来
一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：         
1）先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉     
2）新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量              
3）然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue       
4）接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据         
5）这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据           
6）等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息            

### 6.Kafka为什么速度快
普通的服务器，Kafka也可以轻松支持每秒百万级的写入请求，超过了大部分的消息中间件，这种特性也使得Kafka在日志处理等海量数据场景广泛应用。它的特点就是高吞吐，下面从数据写入和读取两方面分析，为什么Kafka速度这么快。

#### 写入数据
Kafka会把消息写入磁盘，保证数据不会丢失，为了优化写入速度，它用顺序写入和MMFile。

顺序写入：据说，磁盘的顺序读写速度和内存基本持平，所以kafka在写入数据就用的顺序写，每一个Partition其实都是一个文件 ，收到消息后Kafka会把数据插入到文件末尾，但是这种方法有一个缺点就是无法删除数据，offset是只有consumer知道的，kafka不知道这个offset，一般情况下SDK会把它保存到Zookeeper里面，所以需要给Consumer提供zookeeper的地址。但是不删除的话，内存肯定会被撑爆，所以Kafka提供了两种策略来删除，一是基于时间，二是基于partition文件大小。

Memory Mapped Files：即便是顺序写入磁盘，硬盘的访问速度还是追不上内存，所以数据并不是实时的写入磁盘，mmf它的工作原理是直接利用操作系统的Page来实现文件到物理内存的直接映射，完成映射之后你对物理内存的操作会被同步到硬盘上（操作系统在适当的时候），通过mmap，进程像读写硬盘一样读写内存（当然是虚拟机内存），也不必关心内存的大小有虚拟内存为我们兜底，使用这种方式可以获取很大的I/O提升，省去了用户空间到内核空间复制的开销，但也有一个很明显的缺陷——不可靠，写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。

Kafka提供了一个参数——producer.type来控制是不是主动flush，如果Kafka写入到mmap之后就立即flush然后再返回Producer叫 同步 (sync)；写入mmap之后立即返回Producer不调用flush叫异步 (async)。

#### 读取数据
Kafka在读取磁盘时做了哪些优化？

基于sendfile实现Zero Copy：
传统模式下，当需要对一个文件进行传输的时候，其具体流程细节如下：

1.调用read函数，文件数据被copy到内核缓冲区              
2.read函数返回，文件数据从内核缓冲区copy到用户缓冲区        
3.write函数调用，将文件数据从用户缓冲区copy到内核与socket相关的缓冲区。         
4.数据从socket缓冲区copy到相关协议引擎。          

在这个过程当中，文件数据实际上是经过了四次copy操作：硬盘—>内核buf—>用户buf—>socket相关缓冲区—>协议引擎

而sendfile系统调用则提供了一种减少以上多次copy：sendfile(socket, file, len);

1.sendfile系统调用，文件数据被copy至内核缓冲区    
2.再从内核缓冲区copy至内核中socket相关的缓冲区    
3.最后再socket相关的缓冲区copy到协议引擎     


Kafka速度的秘诀在于，它把所有的消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络IO损耗，通过mmap提高I/O速度，写入数据的时候由于单个Partion是末尾添加所以速度最优；读取数据的时候配合sendfile直接暴力输出。
